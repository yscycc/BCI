{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fxcjo1-JeCDN","executionInfo":{"status":"ok","timestamp":1714176386017,"user_tz":240,"elapsed":1040,"user":{"displayName":"Shuchen Yang","userId":"02336666636710721919"}},"outputId":"7a7639d4-7021-4be5-e363-9b09c94be1b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"8yw60itXFWFX"},"source":["Algorithm Overview:\n","*   Features: LMP of lowpassed signal at 3.5 Hz and bandpower of 6 bandpassed signal at 6 different freq bands\n","*   R matrix then catboost\n","*   A\n","*   List item\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mLMkfE1_FQGf"},"outputs":[],"source":["#Set up the notebook environment\n","!pip install catboost xgboost lightgbm scikit-learn\n","import catboost\n","from catboost import CatBoostRegressor\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from scipy.stats import pearsonr\n","from scipy import signal as sig\n","from scipy.io import loadmat\n","from scipy.signal import welch, butter, filtfilt\n","from tqdm import tqdm\n","from scipy.signal import decimate\n","from sklearn.model_selection import train_test_split\n","from scipy.signal import stft\n","from scipy.interpolate import CubicSpline\n","from sklearn.preprocessing import StandardScaler\n","from scipy.io import savemat"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1POJawetMTfm"},"outputs":[],"source":["# Load Training data\n","train_data = loadmat('/content/drive/Shareddrives/BE 5210 Shared Drive/Xuanbei/V4/raw_training_data.mat')\n","test_data = loadmat('/content/drive/Shareddrives/BE 5210 Shared Drive/Xuanbei/V4/leaderboard_data.mat')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vhybLcZq-cpm"},"outputs":[],"source":["# Assign Training & Testing Dataset\n","train_ecog = train_data['train_ecog']\n","train_dg = train_data['train_dg']\n","test_ecog = test_data['leaderboard_ecog']\n","\n","# ECoG Training\n","train_ecog1 = np.vstack(train_ecog[0])\n","train_ecog2 = np.vstack(train_ecog[1])\n","train_ecog3 = np.vstack(train_ecog[2])\n","\n","# Glove Training Data\n","train_dg1 = np.vstack(train_dg[0])\n","train_dg2 = np.vstack(train_dg[1])\n","train_dg3 = np.vstack(train_dg[2])\n","\n","# EcoG Testing\n","test_ecog1 = np.vstack(test_ecog[0])\n","test_ecog2 = np.vstack(test_ecog[1])\n","test_ecog3 = np.vstack(test_ecog[2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_HwweJ9Vc27Y"},"outputs":[],"source":["def filter_signal(raw_ecog,fs):\n","    \"\"\"\n","    Filter the ECoG signal using Butterworth filters.\n","\n","    Parameters:\n","    - raw_ecog: The raw ECoG signal.\n","    - fs: The sampling frequency of the ECoG signal.\n","\n","    Returns:\n","    - down_low_ecog: The filtered ECoG signal.\n","    \"\"\"\n","    lowcut = 3.5  # Low cut-off frequency in Hz\n","    order = 4\n","    notch_freq = 60\n","    notch_Q = 30\n","    down_freq = 20\n","    num_samp_decimate = int(raw_ecog.shape[0]/(fs/down_freq))\n","    chan_num = raw_ecog.shape[1]\n","    relevant_freq_bands = [ (5,8), (8,12), (12,24), (24,34), (34,60), (100,200)]\n","\n","    # Calculate normalized cut-off frequencies\n","    low = lowcut / (fs*0.5)\n","\n","    # Design Butterworth filters\n","    b, a = butter(order, low, btype='low', analog=False)\n","    b_notch, a_notch = sig.iirnotch(notch_freq, notch_Q, fs)\n","    downsample_factor = int(fs / down_freq)\n","    down_low_ecog = np.zeros([raw_ecog.shape[0],chan_num])\n","\n","    for num in range(chan_num):\n","    # Apply low-pass filtering and notch filter to the ECoG data\n","        filtered_ecog = filtfilt(b, a, raw_ecog[:,num])\n","        down_low_ecog[:,num] = filtfilt(b_notch, a_notch, filtered_ecog)\n","\n","    bandpass_signal = []\n","    for band in relevant_freq_bands:\n","        start, end = band\n","        start_freq = start/(fs*.5)\n","        end_freq = end/(fs*.5)\n","        b_band, a_band = butter(order,[start_freq,end_freq],btype= 'band',analog = False)\n","\n","        filtered_channel = np.zeros([raw_ecog.shape[0],chan_num])\n","        for num in range(chan_num):\n","          filtered_band = filtfilt(b_band,a_band, raw_ecog[:,num])\n","          filtered_channel[:,num] = filtered_band\n","        bandpass_signal.append(filtered_channel)\n","\n","    # Assign BandPass\n","    bandpass_signal = np.hstack(bandpass_signal)\n","    bandpass1 = bandpass_signal[:,0:chan_num]\n","    bandpass2 = bandpass_signal[:,chan_num:2*chan_num]\n","    bandpass3 = bandpass_signal[:,2*chan_num:3*chan_num]\n","    bandpass4 = bandpass_signal[:,3*chan_num:4*chan_num]\n","    bandpass5 = bandpass_signal[:,4*chan_num:5*chan_num]\n","    bandpass6 = bandpass_signal[:,5*chan_num:]\n","\n","    return down_low_ecog, bandpass1, bandpass2, bandpass3, bandpass4, bandpass5, bandpass6\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wlX-bvT2z2op"},"outputs":[],"source":["def hjorth_params(signal):\n","    \"\"\"\n","    Calculate Hjorth parameters: activity, mobility, and complexity.\n","\n","    Parameters:\n","    - signal: The input signal.\n","\n","    Returns:\n","    - activity: The activity parameter.\n","    - mobility: The mobility parameter.\n","    - complexity: The complexity parameter.\n","    \"\"\"\n","    activity = np.var(signal)\n","    grad = np.diff(signal)\n","    grad_activity = np.var(grad)\n","    mobility = np.sqrt(grad_activity / activity)\n","\n","    grad2 = np.diff(grad)\n","    grad2_activity = np.var(grad2)\n","    complexity = np.sqrt(grad2_activity / grad_activity) / mobility\n","\n","    return activity, mobility, complexity"]},{"cell_type":"code","source":["def get_features(lowpass, bandpass1, bandpass2, bandpass3, bandpass4, bandpass5, bandpass6):\n","    \"\"\"\n","    Calculate the features for a window.\n","\n","    Parameters:\n","    - lowpass: The low-passed signal.\n","    - bandpass 1 - 6: The band-passed signal.\n","\n","    Returns:\n","    - window_feat_normalized: The normalized features.\n","    \"\"\"\n","\n","    num_samples, num_channels = lowpass.shape\n","    num_features = 10  # Including 3 new Hjorth parameters\n","    features = np.zeros((num_channels, num_features))\n","\n","    for chan in range(num_channels):\n","        lmp = np.mean(lowpass[:,chan],axis=0)\n","        features[chan,0] = lmp\n","\n","        power1 = np.sum(np.square(bandpass1[:,chan]),axis=0)\n","        features[chan,1] = power1\n","        power2 = np.sum(np.square(bandpass2[:,chan]),axis=0)\n","        features[chan,2] = power2\n","        power3 = np.sum(np.square(bandpass3[:,chan]),axis=0)\n","        features[chan,3] = power3\n","        power4 = np.sum(np.square(bandpass4[:,chan]),axis=0)\n","        features[chan,4] = power4\n","        power5 = np.sum(np.square(bandpass5[:,chan]),axis=0)\n","        features[chan,5] = power5\n","        power6 = np.sum(np.square(bandpass6[:,chan]),axis=0)\n","        features[chan,6] = power6\n","\n","        # Hjorth parameters for the raw ECoG channel\n","        activity, mobility, complexity = hjorth_params(lowpass[:,chan])\n","        features[chan,7] = activity\n","        features[chan,8] = mobility\n","        features[chan,9] = complexity\n","\n","    scaler = StandardScaler()\n","    window_feat_normalized = scaler.fit_transform(features)\n","    return window_feat_normalized"],"metadata":{"id":"h-Z_b3vbq0TV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L2B8dzmua6Mq"},"outputs":[],"source":["def NumWins(x,fs,winLen,winDisp):\n","  \"\"\"\n","  Calculate the number of windows in a signal.\n","\n","  Parameters:\n","  - x: The input signal.\n","  - fs: The sampling frequency.\n","  - winLen: The length of each window in seconds.\n","  - winDisp: The overlap between windows in seconds.\n","\n","  Returns:\n","  - num: The number of windows.\n","  \"\"\"\n","  xLen = int(winLen * fs)\n","  samDisp = int(winDisp * fs)\n","  num = 0\n","  result = [];\n","  for i in np.arange(0, len(x), samDisp):\n","     window = x[i:i+xLen]\n","     num = num + 1\n","     if len(window) < xLen:\n","      num = num - 1\n","\n","  return num"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VyicgeYnJbZr"},"outputs":[],"source":["def get_windowed_feats(raw_ecog, fs, window_length,window_overlap):\n","    \"\"\"\n","    Get the windowed features for training.\n","\n","    Parameters:\n","    - raw_ecog: The raw ECoG data array\n","    - fs: The sampling frequency\n","    - window_length: The length of each window in seconds\n","    - window_overlap: The overlap between windows in seconds\n","\n","    Returns:\n","    - all_feats: The windowed features array\n","    \"\"\"\n","    # Apply Filters\n","    lowpass, bandpass1, bandpass2, bandpass3, bandpass4, bandpass5, bandpass6 = filter_signal(raw_ecog, fs)\n","\n","    # Assuming NumWins is defined elsewhere\n","    window_samples = int(window_length * fs)\n","    overlap_samples = int(window_overlap * fs)\n","    num_windows = NumWins(raw_ecog,fs,window_length,window_overlap)\n","\n","    # Initialize features array\n","    features = []\n","    for i in tqdm(range(num_windows)):\n","        window_start = i * overlap_samples\n","        window_end = window_start+window_samples\n","        lowpass_win = lowpass[window_start:window_end]\n","        bandpass1_win = bandpass1[window_start:window_end]\n","        bandpass2_win = bandpass2[window_start:window_end]\n","        bandpass3_win = bandpass3[window_start:window_end]\n","        bandpass4_win = bandpass4[window_start:window_end]\n","        bandpass5_win = bandpass5[window_start:window_end]\n","        bandpass6_win = bandpass6[window_start:window_end]\n","        window_feat = get_features(lowpass_win,bandpass1_win,bandpass2_win,bandpass3_win,bandpass4_win,bandpass5_win,bandpass6_win)\n","        features.append(window_feat.flatten())\n","\n","    all_feats = np.array(features)\n","\n","    return all_feats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4UUtXyye-yvD"},"outputs":[],"source":["# Sampling Tuning\n","window_length = 0.15\n","window_overlap = 0.05\n","fs = 1000\n","N_win = 20\n","\n","# CatBoost Hyperparameters\n","cat_iter = 2500\n","cat_dept = 5\n","cat_leaf = 4\n","cat_learnr = 0.05\n","\n","# Smoothing & Noise Reduction\n","window_size = 210"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9z9KPyMdOp83"},"outputs":[],"source":["# Feature Extraction from Training set\n","train_feat1 = get_windowed_feats(train_ecog1, fs, window_length, window_overlap)\n","train_feat2 = get_windowed_feats(train_ecog2, fs, window_length, window_overlap)\n","train_feat3 = get_windowed_feats(train_ecog3, fs, window_length, window_overlap)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y2w6Zuo0AhZk"},"outputs":[],"source":[" def create_R_matrix(features, N):\n","    \"\"\"\n","    Create the response matrix for training.\n","\n","    Parameters:\n","    - features: The windowed features array\n","    - N: The window size\n","\n","    Returns:\n","    - R: The response matrix\n","    \"\"\"\n","    # First N-1 rows to beginning of features matrix\n","    adjusted_features = np.vstack([features[:N-1], features])\n","\n","    # Number of total instances after adjustment\n","    M_prime = adjusted_features.shape[0] - (N - 1)\n","\n","    # Initialize response matrix R\n","    num_features = features.shape[1]\n","    R = np.zeros((M_prime, N * num_features + 1))  # +1 for the intercept term\n","\n","    # Fill in R\n","    for i in range(M_prime):\n","        #extract N consecutive windows of features\n","        consecutive_features = adjusted_features[i:i+N].flatten()\n","        #fill corresponding row in R, adding 1 as the last column\n","        R[i, 1:] = consecutive_features\n","        R[i, 0] = 1  # Intercept term\n","\n","    return R"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ezag4xqjAiGB"},"outputs":[],"source":["# R Matrices from Training Data\n","R1 = create_R_matrix(train_feat1, N = N_win)\n","R2 = create_R_matrix(train_feat2, N = N_win)\n","R3 = create_R_matrix(train_feat3, N = N_win)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_H40u5Onx3Z"},"outputs":[],"source":["# Feature Extraction from Testing Data\n","test_feat1 = get_windowed_feats(test_ecog1, fs, window_length, window_overlap)\n","test_feat2 = get_windowed_feats(test_ecog2, fs, window_length, window_overlap)\n","test_feat3 = get_windowed_feats(test_ecog3, fs, window_length, window_overlap)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ikS1uvlbHkxz"},"outputs":[],"source":["# R Matrices from Testing Data\n","test_R1 = create_R_matrix(test_feat1, N=N_win)\n","test_R2 = create_R_matrix(test_feat2, N=N_win)\n","test_R3 = create_R_matrix(test_feat3, N=N_win)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OppZKl9H_Vz"},"outputs":[],"source":["def get_windowed_target(glove_data, window_length, window_overlap, fs=1000):\n","    \"\"\"\n","    Get the windowed target glove data for training.\n","\n","    Parameters:\n","    - glove_data: The glove data array\n","    - window_length: The length of each window in seconds\n","    - window_overlap: The overlap between windows in seconds\n","    - fs: The sampling frequency in Hz\n","\n","    Returns:\n","    - targets: The windowed target glove data array\n","    \"\"\"\n","    samp_length = int(fs * (window_length))\n","    samp_overlap = int(fs * (window_overlap))\n","\n","    num_windows = NumWins(glove_data,fs,window_length,window_overlap)\n","    targets = []\n","\n","    for i in range(num_windows):\n","        start_idx = i * samp_overlap\n","        end_idx = start_idx + samp_length\n","        window = glove_data[start_idx:end_idx, :]\n","        targets.append(np.mean(window, axis=0))  # Example: mean over the window\n","\n","    return np.array(targets)"]},{"cell_type":"code","source":["# Windowing target glove data\n","target_1 = get_windowed_target(train_dg1, window_length,window_overlap)\n","target_2 = get_windowed_target(train_dg2, window_length,window_overlap)\n","target_3 = get_windowed_target(train_dg3, window_length,window_overlap)"],"metadata":{"id":"4EAzudXhockl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":316574,"status":"ok","timestamp":1714179861365,"user":{"displayName":"Shuchen Yang","userId":"02336666636710721919"},"user_tz":240},"outputId":"05cae829-2768-47ac-dafa-f2d41e763d50","id":"YX7j9Fiov_Fx"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<catboost.core.CatBoostRegressor at 0x785850a8b550>"]},"metadata":{},"execution_count":89}],"source":["# CatBoost Models Training\n","cat_model1 = CatBoostRegressor(iterations = cat_iter, depth = cat_dept, l2_leaf_reg = cat_leaf, learning_rate = cat_learnr, loss_function = 'MultiRMSE', verbose = False, per_float_feature_quantization = '0:border_count=1024', task_type = 'GPU', boosting_type = 'Plain')\n","cat_model1.fit(R1[:, 1:], target_1)\n","\n","cat_model2 = CatBoostRegressor(iterations = cat_iter, depth = cat_dept, l2_leaf_reg = cat_leaf, learning_rate = cat_learnr, loss_function = 'MultiRMSE',verbose = False, per_float_feature_quantization = '0:border_count=1024', task_type = 'GPU', boosting_type = 'Plain')\n","cat_model2.fit(R2[:, 1:], target_2)\n","\n","cat_model3 = CatBoostRegressor(iterations = cat_iter, depth = cat_dept, l2_leaf_reg = cat_leaf, learning_rate = cat_learnr, loss_function = 'MultiRMSE', verbose = False, per_float_feature_quantization = '0:border_count=1024', task_type = 'GPU', boosting_type = 'Plain')\n","cat_model3.fit(R3[:, 1:], target_3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wg4QeV6kP_R2"},"outputs":[],"source":["# Save Trained Models\n","filename1 = 'cat_model1.pk1'\n","pickle.dump(cat_model1, open(filename1, 'wb'))\n","\n","filename2 = 'cat_model2.pk1'\n","pickle.dump(cat_model2, open(filename2, 'wb'))\n","\n","filename3 = 'cat_model3.pk1'\n","pickle.dump(cat_model3, open(filename3, 'wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PLPeZxcNJYdp"},"outputs":[],"source":["# Make Predictions\n","predicted_1 = cat_model1.predict(test_R1[:, 1:])\n","predicted_2 = cat_model2.predict(test_R2[:, 1:])\n","predicted_3 = cat_model3.predict(test_R3[:, 1:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XYoUUijvX-Kp"},"outputs":[],"source":["def interpolate(prediction, original_length, desired_length):\n","    \"\"\"\n","    Interpolate the prediction to the desired length.\n","\n","    Parameters:\n","    - prediction: The prediction array\n","    - original_length: The length of the original prediction\n","    - desired_length: The desired length of the prediction\n","\n","    Returns:\n","    - interpolated_prediction: The interpolated prediction array\n","    \"\"\"\n","\n","    # Step 1: Create a time array for the original prediction\n","    original_time = np.linspace(0, 1, original_length)\n","\n","    # Step 2: Create a time array for the desired length\n","    desired_time = np.linspace(0, 1, desired_length)\n","\n","    # Step 3: Interpolate each column separately using cubic spline\n","    interpolated_prediction = np.zeros((desired_length, prediction.shape[1]))\n","    for i in range(prediction.shape[1]):\n","        cs = CubicSpline(original_time, prediction[:, i])\n","        interpolated_prediction[:, i] = cs(desired_time)\n","\n","    return interpolated_prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JYXmlRIPYCk7"},"outputs":[],"source":["# Get Lengths of Predictions and Testing Sets\n","original_length = predicted_1.shape[0]\n","desired_length = test_ecog1.shape[0]\n","\n","# Interpolate Predictions to Match Desired Length (Testing Length)\n","inter_prediction1 = interpolate(predicted_1, original_length, desired_length)\n","inter_prediction2 = interpolate(predicted_2, original_length, desired_length)\n","inter_prediction3 = interpolate(predicted_3, original_length, desired_length)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ACnc37ee9fp"},"outputs":[],"source":["def moving_average(data, window_size):\n","    \"\"\"\n","    Apply a moving average filter to the data.\n","\n","    Parameters:\n","    - data: Input data array\n","    - window_size: Size of the moving average window\n","\n","    Returns:\n","    - smoothed_data: Smoothed data array\n","    \"\"\"\n","\n","    all_data = []\n","    for finger in range(5):\n","      smoothed_data = np.convolve(data[:,finger], np.ones(window_size)/window_size, mode = 'same')\n","      all_data.append(smoothed_data)\n","    all_data = np.vstack(all_data)\n","\n","    return all_data.T"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvZM5KX5e_XA"},"outputs":[],"source":["# Smoothing the Prediction for Noise Reduction\n","moving_pred1 = moving_average(inter_prediction1, window_size)\n","moving_pred2 = moving_average(inter_prediction2, window_size)\n","moving_pred3 = moving_average(inter_prediction3, window_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ebthffZnStZ"},"outputs":[],"source":["# Visualize the 3rd Prediction\n","plt.plot(np.linspace(0,moving_pred1.shape[0]/1000,num=147500, endpoint=False), moving_pred3[:,0])"]},{"cell_type":"code","source":["# Visualize the Predictions\n","moving_pred1, moving_pred2, moving_pred3"],"metadata":{"id":"SvNzQB9M-2jE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KR7V5l6ckqhq"},"outputs":[],"source":["# Create Submission Array & Save\n","predictions = np.zeros((3,1), dtype=object)\n","\n","predictions[0,0] = moving_pred1\n","predictions[1,0] = moving_pred2\n","predictions[2,0] = moving_pred3\n","\n","savemat('predictions.mat', {'predicted_dg':predictions})\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}